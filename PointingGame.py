import streamlit as st
import tensorflow as tf
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions
import numpy as np
import cv2
from PIL import Image
import math
import pandas as pd
from googletrans import Translator
import os
import random
import time
from streamlit_image_coordinates import streamlit_image_coordinates
from importlib.metadata import version, PackageNotFoundError

# --- 1. å®šæ•°ã¨åˆæœŸè¨­å®š ---

IMG_SIZE = (224, 224)
LAST_CONV_LAYER_NAME = "out_relu"
IMAGE_FOLDER = "images"
EXAMPLE_IMAGE_PATH = "practice.jpg"

# --- 2. è¨€èªè¾æ›¸ (æ—¥æœ¬èª / English) ---
TEXT = {
    'ja': {
        'title': "ğŸ§ª AIã®è¦–ç‚¹ã‚’æ¢ã‚Œï¼ç”»åƒèªè­˜å®Ÿé¨“",
        'sidebar_menu': "ğŸ”§ ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
        'btn_reset': "å®Ÿé¨“ã‚’ãƒªã‚»ãƒƒãƒˆ (æœ€åˆã«æˆ»ã‚‹)",
        'welcome_desc': """
        ã“ã®å®Ÿé¨“ã¯ã€ã€ŒAIï¼ˆäººå·¥çŸ¥èƒ½ï¼‰ãŒç”»åƒã®ã©ã“ã‚’è¦‹ã¦åˆ¤æ–­ã—ãŸã‹ã€ã‚’äººé–“ãŒã©ã‚Œãã‚‰ã„äºˆæ¸¬ã§ãã‚‹ã‹èª¿æŸ»ã™ã‚‹ã‚‚ã®ã§ã™ã€‚
        
        **å®Ÿé¨“ã®æµã‚Œ:**
        1. **ç·´ç¿’ãƒ¢ãƒ¼ãƒ‰:** æ“ä½œã«æ…£ã‚Œã‚‹ãŸã‚ã€1æšã ã‘ç·´ç¿’ã—ã¾ã™ã€‚
        2. **æœ¬ç•ª:** ãƒ©ãƒ³ãƒ€ãƒ ã«è¡¨ç¤ºã•ã‚Œã‚‹ç”»åƒã§å®Ÿé¨“ã‚’è¡Œã„ã¾ã™ã€‚
        3. **ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆ:** çµæœã«ã¤ã„ã¦ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚
        
        **âš ï¸ é‡è¦ãªæ³¨æ„:**
        æ“ä½œã¯ã€Œã‚¯ãƒªãƒƒã‚¯ï¼ˆç‚¹ï¼‰ã€ã§è¡Œã„ã¾ã™ãŒã€**ã€ŒAIãŒæ³¨ç›®ã—ãŸé ˜åŸŸã®ä¸­å¿ƒã€** ã ã¨æ€ã†å ´æ‰€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚
        ï¼ˆãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆãª1ç‚¹ã§ã¯ãªãã€ã‚ã‚‹ç¨‹åº¦ã®ç¯„å›²ã‚’æ„è­˜ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼‰
        """,
        'input_name': "ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ  ã¾ãŸã¯ è¢«é¨“è€…ID",
        'btn_start_practice': "å…¥åŠ›ã—ã¦ç·´ç¿’ã‚’é–‹å§‹ã™ã‚‹",
        'practice_mode': "ğŸ”° ç·´ç¿’ãƒ¢ãƒ¼ãƒ‰",
        'click_instruction': "ç”»åƒã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€AIã®æ³¨ç›®é ˜åŸŸã®ä¸­å¿ƒã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚",
        'btn_decide': "æ±ºå®šã™ã‚‹",
        'result_score': "ã‚¹ã‚³ã‚¢",
        'result_match': "AIã¨ã®ä¸€è‡´åº¦",
        'res_total': "åˆè¨ˆã‚¹ã‚³ã‚¢",
        'res_avg_score': "å¹³å‡ã‚¹ã‚³ã‚¢",
        'res_avg_time': "å¹³å‡å›ç­”æ™‚é–“",
        'chart_label': "ç”»åƒç•ªå·",
        'likert_opts': ["1.å…¨ããã†æ€ã‚ãªã„", "2.ã‚ã¾ã‚Šãã†æ€ã‚ãªã„", "3.ã©ã¡ã‚‰ã¨ã‚‚è¨€ãˆãªã„", "4.ãã†æ€ã†", "5.å¼·ããã†æ€ã†"],
        'ai_pred': "AIäºˆæ¸¬",
        'ai_breakdown': "AIã®åˆ¤æ–­å†…è¨³",
        'playing_title': "ğŸ§ª å®Ÿé¨“ãƒ—ãƒ¬ã‚¤ä¸­ (æœ¬ç•ª)",
        'difficulty': "Q1. é›£æ˜“åº¦",
        'difficulty_opts': ["ã¨ã¦ã‚‚ç°¡å˜", "ç°¡å˜", "æ™®é€š", "é›£ã—ã„", "ã¨ã¦ã‚‚é›£ã—ã„"],
        'agree_q': "Q2. AIã®åˆ¤æ–­ï¼ˆèµ¤è‰²ï¼‰ã¸ã®ç´å¾—æ„Ÿ",
        'agree_opts': ["ç´å¾—ã§ãã‚‹", "ç´å¾—ã§ããªã„"],
        'disagree_reason': "Q2-1. ç´å¾—ã§ããªã„ç†ç”±ã‚’æ•™ãˆã¦ãã ã•ã„ï¼ˆè‡ªç”±è¨˜è¿°ï¼‰",
        'btn_next': "ç¢ºå®šã—ã¦æ¬¡ã¸é€²ã‚€",
        'finished_title': "ğŸ‰ å…¨ç”»åƒçµ‚äº†ã§ã™ï¼",
        'chart_title': "###### ğŸ“ˆ ç”»åƒã”ã¨ã®ã‚¹ã‚³ã‚¢æ¨ç§»",
        'final_q1': "Q1. å®Ÿé¨“ã¯æ¥½ã—ã‚ã¾ã—ãŸã‹ï¼Ÿ",
        'final_q2': "Q2. ã‚¹ã‚³ã‚¢ã‚’æ„è­˜ã—ã¾ã—ãŸã‹ï¼Ÿ",
        'final_q3': "Q3. æ“ä½œã¯åˆ†ã‹ã‚Šã‚„ã™ã‹ã£ãŸã§ã™ã‹ï¼Ÿ",
        'final_q4': "Q4. è‡ªç”±è¨˜è¿°ï¼ˆæ„Ÿæƒ³ã‚„æ°—ã¥ãï¼‰",
        'btn_download': "ğŸ’¾ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)",
        'btn_confirm': "å›ç­”ã‚’ç¢ºå®šã™ã‚‹",
        'btn_end': "ğŸ”„ å®Ÿé¨“ã‚’çµ‚äº†ã—ã¦ãƒªã‚»ãƒƒãƒˆ (ãƒˆãƒƒãƒ—ã¸æˆ»ã‚‹)",
        'warning_line': "âš ï¸ é‡è¦ï¼šLINEã‚„Instagramã‹ã‚‰é–‹ã„ã¦ã„ã‚‹æ–¹ã¸",
        'info_line': "ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ãŒã§ããªã„å ´åˆãŒã‚ã‚‹ãŸã‚ã€å³ä¸Šã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã (Safari/Chrome)ã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
        'knowledge_q': "Q. AI(äººå·¥çŸ¥èƒ½)ã«ã¤ã„ã¦ã®çŸ¥è­˜ãƒ»åˆ©ç”¨çµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        'knowledge_opts': (
            "1. å…¨ãçŸ¥ã‚‰ãªã„ / ä½¿ã£ãŸã“ã¨ãŒãªã„",
            "2. ChatGPTã‚„Geminiãªã©ã®ç”ŸæˆAIã‚’ä½¿ã£ãŸã“ã¨ãŒã‚ã‚‹",
            "3. AIã®ä»•çµ„ã¿ï¼ˆæ©Ÿæ¢°å­¦ç¿’ã®åŸç†ãªã©ï¼‰ã‚’ã‚ã‚‹ç¨‹åº¦ç†è§£ã—ã¦ã„ã‚‹",
            "4. AIã®ç ”ç©¶ãƒ»é–‹ç™ºãƒ»å®Ÿè£…ã®çµŒé¨“ãŒã‚ã‚‹"
        )
    },
    'en': {
        'title': "ğŸ§ª Explore AI's Vision! Experiment",
        'sidebar_menu': "ğŸ”§ Admin Menu",
        'btn_reset': "Reset Experiment",
        'welcome_desc': """
        This experiment investigates how well humans can predict "where AI looks when making decisions".
        
        **Flow:**
        1. **Practice:** Try 1 image to get used to it.
        2. **Main:** Experiment with randomly displayed images.
        3. **Survey:** Please provide feedback on the results.
        
        **âš ï¸ Important:**
        Please click the **"Center of the area AI focused on"**.
        (Think of it as an area, not just a single pixel point.)
        """,
        'input_name': "Nickname or ID",
        'btn_start_practice': "Start Practice",
        'practice_mode': "ğŸ”° Practice Mode",
        'click_instruction': "Click the image to specify the center of AI's attention.",
        'btn_decide': "Submit",
        'result_score': "Score",
        'result_match': "Match Rate",
        'res_total': "Total Score",
        'res_avg_score': "Avg Score",
        'res_avg_time': "Avg Time",
        'chart_label': "Image ID",
        'likert_opts': ["1.Strongly Disagree", "2.Disagree", "3.Neutral", "4.Agree", "5.Strongly Agree"],
        'ai_pred': "AI Prediction",
        'ai_breakdown': "AI Prediction Breakdown",
        'playing_title': "ğŸ§ª Main Experiment",
        'difficulty': "Q1. Difficulty",
        'difficulty_opts': ["Very Easy", "Easy", "Normal", "Hard", "Very Hard"],
        'agree_q': "Q2. Agreement with AI's focus (Red area)",
        'agree_opts': ["Agree", "Disagree"],
        'disagree_reason': "Q2-1. Please describe why you disagree",
        'btn_next': "Confirm & Next",
        'finished_title': "ğŸ‰ All Images Completed!",
        'chart_title': "###### ğŸ“ˆ Score Progress",
        'final_q1': "Q1. Did you enjoy the experiment?",
        'final_q2': "Q2. Did you focus on the score?",
        'final_q3': "Q3. Was the operation easy?",
        'final_q4': "Q4. Comments / Feedback",
        'btn_download': "ğŸ’¾ Download Data (CSV)",
        'btn_confirm': "Confirm Answers",
        'btn_end': "ğŸ”„ Finish & Reset (Back to Top)",
        'warning_line': "âš ï¸ Important: For LINE/Instagram users",
        'info_line': "Please open in standard browser (Safari/Chrome) to ensure data saving.",
        'knowledge_q': "Q. Do you have knowledge/experience with AI?",
        'knowledge_opts': (
            "1. No knowledge / Never used",
            "2. Used Gen-AI (ChatGPT, Gemini, etc.)",
            "3. Understand AI mechanisms (Machine Learning basics)",
            "4. Experience in AI research/development"
        )
    }
}

# --- 3. ãƒ¢ãƒ‡ãƒ«ã¨Grad-CAMè¨ˆç®— ---

@st.cache_resource
def load_model():
    return MobileNetV2(weights='imagenet')

def get_gradcam_data(model, input_img_array, lang='ja'):
    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    grad_model = tf.keras.models.Model(
        inputs=[model.inputs],
        outputs=[model.get_layer(LAST_CONV_LAYER_NAME).output, model.output]
    )

    # å‹¾é…è¨ˆç®—
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(input_img_array)
        pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    grads = tape.gradient(class_channel, last_conv_layer_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    heatmap_np = heatmap.numpy()

    # Top3äºˆæ¸¬ã¨ç¿»è¨³
    decoded_list = decode_predictions(model.predict(input_img_array), top=3)[0]
    top3_info = [] 
    translator = Translator()

    for i, (id, label, prob) in enumerate(decoded_list):
        if lang == 'ja':
            try:
                display_label = translator.translate(label, src='en', dest='ja').text
            except:
                display_label = label
            info_text = f"{i+1}ä½: {display_label} ({label}) - {prob*100:.1f}%"
        else:
            display_label = label
            info_text = f"#{i+1}: {display_label} - {prob*100:.1f}%"
        
        top3_info.append(info_text)

    # 1ä½ãƒ©ãƒ™ãƒ«
    top1_label_en = decoded_list[0][1]
    top1_confidence = decoded_list[0][2]
    
    if lang == 'ja':
        try:
            top1_ja = translator.translate(top1_label_en, src='en', dest='ja').text
            prediction_label = f"{top1_ja} ({top1_label_en})"
        except:
            prediction_label = top1_label_en
    else:
        prediction_label = top1_label_en

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—åº§æ¨™è¨ˆç®—
    result_coords = np.unravel_index(np.argmax(heatmap_np), heatmap_np.shape)
    y_norm = result_coords[0] / heatmap_np.shape[0]
    x_norm = result_coords[1] / heatmap_np.shape[1]
    
    true_point = (int((x_norm + 0.5/heatmap_np.shape[1]) * IMG_SIZE[0]), 
                  int((y_norm + 0.5/heatmap_np.shape[0]) * IMG_SIZE[1]))

    return heatmap_np, prediction_label, top1_confidence, true_point, top3_info

def calculate_score(user_point, true_point):
    return math.sqrt((user_point[0] - true_point[0])**2 + (user_point[1] - true_point[1])**2)

def calculate_score_by_heatmap(user_point, heatmap_np):
    h, w = heatmap_np.shape
    grid_x = int(user_point[0] / IMG_SIZE[0] * w)
    grid_y = int(user_point[1] / IMG_SIZE[1] * h)
    grid_x = min(max(grid_x, 0), w - 1)
    grid_y = min(max(grid_y, 0), h - 1)
    
    intensity = heatmap_np[grid_y, grid_x]
    score = int(intensity * 100)
    return score, intensity

def draw_crosshair(img_pil, x, y, color=(0, 0, 255)):
    img_cv = np.array(img_pil.resize(IMG_SIZE))
    cv2.line(img_cv, (0, y), (IMG_SIZE[0], y), color, 1)
    cv2.line(img_cv, (x, 0), (x, IMG_SIZE[1]), color, 1)
    cv2.circle(img_cv, (x, y), 5, color, -1)
    return Image.fromarray(img_cv)

def generate_result_image(original_img_pil, heatmap_np, user_point, true_point):
    img_cv = np.array(original_img_pil.resize(IMG_SIZE))
    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR)
    
    heatmap = cv2.resize(heatmap_np, IMG_SIZE)
    heatmap_uint8 = np.uint8(255 * heatmap)
    colormap = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
    
    superimposed_img = cv2.addWeighted(img_cv, 0.6, colormap, 0.4, 0)
    
    # User (é’) - ç‚¹ã¨å††
    cv2.circle(superimposed_img, user_point, 5, (255, 0, 0), -1) 
    cv2.circle(superimposed_img, user_point, 25, (255, 0, 0), 1)
    cv2.putText(superimposed_img, "YOU", (user_point[0]+8, user_point[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)

    # AI (èµ¤) - ç‚¹ã®ã¿
    cv2.circle(superimposed_img, true_point, 5, (0, 0, 255), -1)
    cv2.putText(superimposed_img, "AI", (true_point[0]+8, true_point[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

    return Image.fromarray(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))

# --- 4. ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

def main():
    st.set_page_config(page_title="Grad-CAM Experiment", layout="centered")

    if 'language' not in st.session_state:
        st.session_state.language = 'ja'

    # è¨€èªè¾æ›¸ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
    T = TEXT[st.session_state.language]

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.subheader("ğŸŒ Language")
        lang_select = st.radio(
            "Language", ('æ—¥æœ¬èª', 'English'),
            index=0 if st.session_state.language == 'ja' else 1
        )
        if (lang_select == 'æ—¥æœ¬èª' and st.session_state.language != 'ja') or \
           (lang_select == 'English' and st.session_state.language != 'en'):
            st.session_state.language = 'ja' if lang_select == 'æ—¥æœ¬èª' else 'en'
            st.rerun()

        st.markdown("---")
        st.write(T['sidebar_menu'])
        if st.button(T['btn_reset']):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
            
        st.markdown("---")
        try:
            coord_ver = version("streamlit-image-coordinates")
        except PackageNotFoundError:
            coord_ver = "unknown"
        st.caption("ğŸ“š Environment")
        st.code(f"TF: {tf.__version__}\nImgCoord: {coord_ver}", language="text")

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    if 'model' not in st.session_state:
        st.session_state.model = load_model()
    
    if 'all_results' not in st.session_state:
        st.session_state.all_results = []

    if 'game_state' not in st.session_state:
        st.session_state.game_state = 'welcome'

    # --- WELCOME ---
    if st.session_state.game_state == 'welcome':
        # âš ï¸ è­¦å‘Šã¯ã“ã“ã«ç§»å‹•
        st.warning(T['warning_line'])
        st.info(T['info_line'])
        
        st.title(T['title'])
        st.markdown(T['welcome_desc'])
        st.markdown("---")
        
        with st.form("entry_form"):
            input_name = st.text_input(T['input_name'])
            input_knowledge = st.radio(T['knowledge_q'], T['knowledge_opts'], index=1)
            start_submitted = st.form_submit_button(T['btn_start_practice'], type="primary")

        if start_submitted:
            if not input_name:
                st.error("Please enter a name.")
            else:
                st.session_state.user_name = input_name
                st.session_state.ai_knowledge = input_knowledge
                st.session_state.game_state = 'example_init'
                st.rerun()

    # --- EXAMPLE INIT ---
    elif st.session_state.game_state == 'example_init':
        if not os.path.exists(EXAMPLE_IMAGE_PATH):
             st.error(f"Error: {EXAMPLE_IMAGE_PATH} not found.")
             st.stop()

        with st.spinner('Loading...'):
            img = Image.open(EXAMPLE_IMAGE_PATH).convert("RGB")
            img_array = preprocess_input(np.expand_dims(np.array(img.resize(IMG_SIZE)), axis=0).astype(np.float32))
            
            heatmap, label, confidence, true_pt, top3_info = get_gradcam_data(
                st.session_state.model, img_array, lang=st.session_state.language
            )

            st.session_state.update({
                'example_img': img,
                'example_heatmap': heatmap,
                'example_true_pt': true_pt,
                'example_label': label,
                'example_top3': top3_info,
                'example_temp_click': None,
                'game_state': 'example_playing'
            })
            st.rerun()

    # --- EXAMPLE PLAYING ---
    elif st.session_state.game_state == 'example_playing':
        st.title(T['practice_mode'])
        
        st.subheader(f"{T['ai_pred']}: **{st.session_state.example_label}**")
        with st.expander(T['ai_breakdown'], expanded=True):
            for info in st.session_state.example_top3:
                st.write(info)
        
        st.write(T['click_instruction'])

        if st.session_state.example_temp_click is None:
             display_img = st.session_state.example_img.resize(IMG_SIZE)
        else:
             display_img = draw_crosshair(st.session_state.example_img, 
                                          st.session_state.example_temp_click[0], 
                                          st.session_state.example_temp_click[1])

        value = streamlit_image_coordinates(display_img, key="example_click", width=IMG_SIZE[0], height=IMG_SIZE[1])

        if value:
            new_point = (value['x'], value['y'])
            if st.session_state.example_temp_click != new_point:
                st.session_state.example_temp_click = new_point
                st.rerun()

        if st.session_state.example_temp_click:
            if st.button(T['btn_decide'], type="primary"):
                user_pt = st.session_state.example_temp_click
                score, intensity = calculate_score_by_heatmap(user_pt, st.session_state.example_heatmap)

                st.session_state.update({
                    'example_score': score,
                    'example_intensity': intensity,
                    'game_state': 'example_result'
                })
                st.rerun()

    # --- EXAMPLE RESULT ---
    elif st.session_state.game_state == 'example_result':
        st.title(T['practice_mode'])
        st.metric(T['result_score'], f"{st.session_state.example_score} / 100", f"{T['result_match']}: {st.session_state.example_intensity*100:.1f}%")
        
        result_img = generate_result_image(st.session_state.example_img, st.session_state.example_heatmap,
                                           st.session_state.example_temp_click, st.session_state.example_true_pt)
        st.image(result_img, caption="YOU(Blue) vs AI(Red)", width=350)
        
        st.markdown("---")
        if st.button("Start Main Experiment", type="primary"):
             st.session_state.game_state = 'setup'
             st.rerun()

    # --- SETUP ---
    elif st.session_state.game_state == 'setup':
        if not os.path.exists(IMAGE_FOLDER):
            st.error(f"Error: '{IMAGE_FOLDER}' folder not found.")
            st.stop()
        
        image_files = [f for f in os.listdir(IMAGE_FOLDER) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        if not image_files:
            st.error(f"Error: No images in '{IMAGE_FOLDER}'.")
            st.stop()
            
        random.shuffle(image_files)
        st.session_state.image_queue = image_files
        st.session_state.total_images = len(image_files)
        st.session_state.all_results = []
        st.session_state.game_state = 'init'
        st.rerun()

    # --- INIT (MAIN) ---
    elif st.session_state.game_state == 'init':
        if not st.session_state.image_queue:
            st.session_state.game_state = 'finished'
            st.rerun()
            return

        selected_file = st.session_state.image_queue.pop()
        image_path = os.path.join(IMAGE_FOLDER, selected_file)
        current_count = st.session_state.total_images - len(st.session_state.image_queue)

        with st.spinner(f'Loading... ({current_count}/{st.session_state.total_images})'):
            img = Image.open(image_path).convert("RGB")
            img_array = preprocess_input(np.expand_dims(np.array(img.resize(IMG_SIZE)), axis=0).astype(np.float32))
            
            heatmap, label, confidence, true_pt, top3_info = get_gradcam_data(
                st.session_state.model, img_array, lang=st.session_state.language
            )
            
            st.session_state.update({
                'original_img': img, 
                'heatmap': heatmap, 
                'true_point': true_pt,
                'label': label,
                'confidence': confidence,
                'top3_info': top3_info,
                'image_filename': selected_file,
                'current_count': current_count,
                'start_time': time.time(),
                'temp_click': None,
                'game_state': 'playing'
            })
            st.rerun()

    # --- PLAYING (MAIN) ---
    elif st.session_state.game_state == 'playing':
        st.title(T['playing_title'])
        st.caption(f"User: {st.session_state.user_name} | {st.session_state.current_count} / {st.session_state.total_images}")
        
        st.subheader(f"{T['ai_pred']}: **{st.session_state.label}**")
        with st.container():
            st.markdown(f"##### {T['ai_breakdown']}")
            for info in st.session_state.top3_info:
                st.text(info)
        
        st.write(T['click_instruction'])
        
        if st.session_state.temp_click is None:
            display_img = st.session_state.original_img.resize(IMG_SIZE)
        else:
            display_img = draw_crosshair(st.session_state.original_img, 
                                        st.session_state.temp_click[0], 
                                        st.session_state.temp_click[1])

        value = streamlit_image_coordinates(display_img, key="click", width=IMG_SIZE[0], height=IMG_SIZE[1])

        if value:
            new_point = (value['x'], value['y'])
            if st.session_state.temp_click != new_point:
                st.session_state.temp_click = new_point
                st.rerun()

        if st.session_state.temp_click:
            if st.button(T['btn_decide'], type="primary"):
                end_time = time.time()
                response_time = end_time - st.session_state.start_time
                user_pt = st.session_state.temp_click
                dist = calculate_score(user_pt, st.session_state.true_point)
                score, intensity = calculate_score_by_heatmap(user_pt, st.session_state.heatmap)
                
                st.session_state.update({
                    'user_point': user_pt, 
                    'score': score, 
                    'dist': dist, 
                    'intensity': intensity,
                    'response_time': response_time,
                    'game_state': 'result'
                })
                st.rerun()

    # --- RESULT (MAIN) ---
    elif st.session_state.game_state == 'result':
        st.metric(T['result_score'], f"{st.session_state.score} / 100", f"{T['result_match']}: {st.session_state.intensity*100:.1f}%")
        
        result_img = generate_result_image(st.session_state.original_img, st.session_state.heatmap, 
                                           st.session_state.user_point, st.session_state.true_point)
        st.image(result_img, caption="YOU(Blue) vs AI(Red)", width=350)

        st.markdown("---")
        
        q_difficulty = st.select_slider(T['difficulty'], options=T['difficulty_opts'], value=T['difficulty_opts'][2])
        st.markdown("---")
        q_agree = st.radio(T['agree_q'], T['agree_opts'], index=0, horizontal=True)
        
        final_reason = ""
        # è‡ªç”±è¨˜è¿°ã®ã¿
        if q_agree == T['agree_opts'][1]: # Disagree
            final_reason = st.text_input(T['disagree_reason'])

        st.markdown("<br>", unsafe_allow_html=True)

        if st.button(T['btn_next'], type="primary"):
            top3_str = " | ".join(st.session_state.top3_info)
            current_data = {
                "user_name": st.session_state.user_name,
                "ai_knowledge": st.session_state.ai_knowledge,
                "image_file": st.session_state.image_filename,
                "prediction_label": st.session_state.label,
                "top3_predictions": top3_str,
                "response_time": st.session_state.response_time,
                "score": st.session_state.score,
                "intensity": st.session_state.intensity,
                "error_px": st.session_state.dist,
                "user_x": st.session_state.user_point[0],
                "user_y": st.session_state.user_point[1],
                "ai_x": st.session_state.true_point[0],
                "ai_y": st.session_state.true_point[1],
                "survey_difficulty": q_difficulty,
                "survey_agree": q_agree,
                "survey_disagree_reason": final_reason,
            }
            st.session_state.all_results.append(current_data)
            st.session_state.game_state = 'init'
            st.rerun()

    # --- FINISHED ---
    elif st.session_state.game_state == 'finished':
        st.title(T['finished_title'])

        if 'survey_completed' not in st.session_state:
            st.session_state.survey_completed = False
        
        if st.session_state.all_results:
            scores = [res['score'] for res in st.session_state.all_results]
            times = [res['response_time'] for res in st.session_state.all_results]
            total_score = sum(scores)
            avg_score = total_score / len(scores) if scores else 0
            avg_time = sum(times) / len(times) if times else 0

            # ç§°å·ã‚·ã‚¹ãƒ†ãƒ (å¤šè¨€èªå¯¾å¿œã¯è¤‡é›‘ã«ãªã‚‹ã®ã§ã‚¢ã‚¤ã‚³ãƒ³ã¨æ•°å€¤ãƒ¡ã‚¤ãƒ³ã§è¡¨ç¤º)
            if avg_score >= 80:
                icon, player_type = "ğŸ‘‘", "AI Synchronizer"
            elif avg_score >= 60 and avg_time < 5.0:
                icon, player_type = "ğŸš€", "Speed Analyst"
            elif avg_score >= 60:
                icon, player_type = "ğŸ§", "Deep Thinker"
            elif avg_score < 40:
                icon, player_type = "ğŸ¨", "Unique Eye"
            else:
                icon, player_type = "âœ¨", "Balancer"

            # ãƒªã‚¶ãƒ«ãƒˆè¡¨ç¤º (CSSã§æ–‡å­—è‰²å›ºå®š)
            st.markdown(f"""
            <div style="padding: 20px; border-radius: 15px; background-color: #f0f2f6; margin-bottom: 20px;">
                <h2 style="text-align: center; color: #31333F;">{icon} {player_type}</h2>
                <hr style="border: 1px solid #ddd;">
                <div style="display: flex; justify-content: space-around; text-align: center;">
                    <div>
                        <p style="font-size: 0.9em; color: gray; margin: 0;">Total</p>
                        <p style="font-size: 1.8em; font-weight: bold; margin: 0; color: #FF4B4B;">{total_score}</p>
                    </div>
                    <div>
                        <p style="font-size: 0.9em; color: gray; margin: 0;">Avg Score</p>
                        <p style="font-size: 1.8em; font-weight: bold; margin: 0; color: #1f77b4;">{avg_score:.1f}</p>
                    </div>
                    <div>
                        <p style="font-size: 0.9em; color: gray; margin: 0;">{T['res_avg_time']}</p>
                        <p style="font-size: 1.8em; font-weight: bold; margin: 0; color: #31333F;">{avg_time:.1f}s</p>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)

            st.write(T['chart_title'])

            chart_col_name = T['chart_label']
            chart_data = pd.DataFrame({
                chart_col_name: range(1, len(scores) + 1),
                'Score': scores
            })
            # set_indexã‚’ä½¿ã£ã¦æ˜ç¤ºçš„ã«xè»¸ã‚’æŒ‡å®š
            st.bar_chart(chart_data.set_index(chart_col_name), color="#FF4B4B")

        else:
            total_score = 0

        st.markdown("---")
        
        #æœ€çµ‚ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆ
        with st.form("final_survey"):
            opts = T['likert_opts']
            q1 = st.select_slider(T['final_q1'], options=opts, value=opts[2])
            q2 = st.select_slider(T['final_q2'], options=opts, value=opts[2])
            q3 = st.select_slider(T['final_q3'], options=opts, value=opts[2])
            comment = st.text_area(T['final_q4'])
            
            confirm_submit = st.form_submit_button(T['btn_confirm'], type="primary")

        if confirm_submit:
            if st.session_state.all_results:
                for res in st.session_state.all_results:
                    res["final_q1"] = q1
                    res["final_q2"] = q2
                    res["final_q3"] = q3
                    res["final_comment"] = comment
                    res["total_score"] = total_score
                
                # ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
                st.session_state.survey_completed = True
                st.rerun() # ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã•ã›ã‚‹

        # --- ãƒ•ãƒ©ã‚°ãŒç«‹ã£ã¦ã„ãŸã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º ---
        if st.session_state.survey_completed:
            df = pd.DataFrame(st.session_state.all_results)
            csv = df.to_csv(index=False).encode('utf-8')
            filename = f"{st.session_state.user_name}_FULL_EXPERIMENT.csv"

            st.success("Thank you! Data is ready.")
            # ğŸ‘‡ ã“ã“ã«æœ¬å½“ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
            st.download_button(
                label=T['btn_download'], 
                data=csv, 
                file_name=filename, 
                mime='text/csv', 
                type='primary'
            )

        st.markdown("---")

        if st.button(T['btn_end']):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()

if __name__ == "__main__":
    main()